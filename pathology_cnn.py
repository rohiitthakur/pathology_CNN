# -*- coding: utf-8 -*-
"""pathology_cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fxI6M-0imc8xS4w0L1Z3zTyc912iTloG
"""

import torch
import random
import numpy as np

import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, TensorDataset

import torchvision
from torchvision import datasets, transforms, models

from torchvision.datasets import ImageFolder

from IPython import get_ipython
import warnings
import pandas as pd

warnings.filterwarnings("ignore")
ipython = get_ipython()

transforms_train = transforms.Compose([
    transforms.ToTensor(),
    # We've computed the mean and variance for this dataset beforehand, so we can plug it in here
    transforms.Normalize((0.1307,), (0.3081,)) 
])
transforms_test =transforms.Compose([
    transforms.ToTensor(),
    # We've computed the mean and variance for this dataset beforehand, so we can plug it in here
    transforms.Normalize((0.1307,), (0.3081,))
])

path  = '/content/drive/MyDrive/pathologyData/'

train_data = datasets.ImageFolder(path + 'train/', transform=transforms_train)


# /content/drive/MyDrive/ISB DL FIles Assignment/pathologyData/foreground/train

test_data = datasets.ImageFolder(path + 'test/', transform = transforms_test)

dataloader_train = DataLoader(
    train_data, batch_size=128, shuffle=True, num_workers = 4
)
dataloader_test = DataLoader(
    test_data, batch_size=128, shuffle=False, num_workers = 4
)

class Image_CNN(nn.Module):

    def train_step(self, batch):
        img, labels = batch
        out = self(img)                  
        loss = F.cross_entropy(out, labels) 
        return loss

    def val_step(self, batch):
        img, labels = batch
        out = self(img)                    
        loss = F.cross_entropy(out, labels)   
        ac_s = accuracy(out, labels)           
        return {'val_loss': loss.detach(), 'val_acc': ac_s}

    def val_epoch_end(self, outputs):
        batch_loss = [x['validation_loss'] for x in outputs]
        epoch_loss = torch.stack(batch_loss).mean()  
        batch_accs = [x['validation_acc'] for x in outputs]
        epoch_acc = torch.stack(batch_accs).mean()     
        return {'validation_loss': epoch_loss.item(), 'validation_acc': epoch_acc.item()}

    def epoch_end(self, epoch, result):
        print("Epoch [{}], training_loss: {:.4f}, validation_loss: {:.4f}, validation_acc: {:.4f}".format(
            epoch, result['training_loss'], result['validation_loss'], result['validation_acc']))

class CNN(Image_CNN):
    def __init__(self):
        super().__init__()
        self.network = nn.Sequential(

            nn.Conv2d(3, 16, kernel_size = 3, padding = 1,stride = 1),
            nn.ReLU(),
            nn.MaxPool2d(2,2),

            nn.Conv2d(16, 8, kernel_size = 3, stride = 1, padding = 1),
            nn.ReLU(),
            nn.MaxPool2d(2,2),
            nn.Flatten(start_dim=1),

            nn.Linear(25*25*8,64),
            nn.Linear(64,2),
            nn.ReLU()
        )

    def forward(self, xb):
        return self.network(xb)

def train(model, data_loader, optimizer, criterion, epoch):
    model.train()
    loss_train = 0
    num_correct = 0
    for batch_idx, (data, target) in enumerate(data_loader):
        data, target = data, target
        optimizer.zero_grad()
        output = model(data)
        loss = criterion(output, target)
        loss.backward()
        optimizer.step()
        loss_train += loss.item()
        prediction = output.argmax(dim=1)
        num_correct += prediction.eq(target).sum().item()
        if batch_idx % 50 == 0:
            print('Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.4f}\tAccuracy: {:.0f}%'.format(
                epoch, batch_idx * len(data), len(data_loader.dataset),
                100. * batch_idx / len(data_loader), loss_train / (batch_idx + 1),
                100. * num_correct / (len(data) * (batch_idx + 1))))
    loss_train /= len(data_loader)
    accuracy = num_correct / len(data_loader.dataset)
    return loss_train, accuracy


def test(model, data_loader, criterion):
    model.eval()
    loss_test = 0
    num_correct = 0
    with torch.no_grad():
        for data, target in data_loader:
            data, target = data, target
            output = model(data)
            loss = criterion(output, target)
            loss_test += loss.item()  # sum up batch loss
            prediction = output.argmax(dim=1)
            num_correct += prediction.eq(target).sum().item()
    loss_test /= len(data_loader)
    accuracy = num_correct / len(data_loader.dataset)
    return loss_test, accuracy

model = CNN()
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001) 

for epoch in range(1, 6):
    loss_train, acc_train = train(model, dataloader_train, optimizer, criterion, epoch)
    print('Epoch {} Train: Loss: {:.4f}, Accuracy: {:.3f}%\n'.format(
        epoch, loss_train, 100. * acc_train))


loss_test, acc_test = test(model, dataloader_test, criterion)
print('Test : Loss: {:.4f}, Accuracy: {:.3f}%\n'.format(loss_test, 100. * acc_test))